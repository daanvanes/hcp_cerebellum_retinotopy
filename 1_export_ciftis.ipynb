{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cifti\n",
    "import numpy as np\n",
    "import os\n",
    "import nibabel as nb\n",
    "import h5py\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pkg_dir = '/home/shared/2018/visual/HCP7TFIXED/'\n",
    "out_dir = '/home/shared/2018/visual/hcp_cerebellum/'\n",
    "\n",
    "orig = cifti.read(os.path.join(pkg_dir,'999999','tfMRI_RETEXP_7T_AP_Atlas_MSMAll_hp2000_clean.dtseries.nii'))\n",
    "series = orig[1][0] # array from 0-300\n",
    "bm = orig[1][1] # cifti brain model\n",
    "\n",
    "wbc = \"\"\"/home/vanes/Downloads/workbench/bin_rh_linux64/wb_command -cifti-separate {cii} \\\n",
    "COLUMN -volume-all {cii_n}_data_sub.nii \\\n",
    "-metric CORTEX_LEFT {cii_n}_L.gii \\\n",
    "-metric CORTEX_RIGHT {cii_n}_R.gii &\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read prf results for all subjects:\n",
    "with h5py.File(os.path.join(pkg_dir,'prfresults.mat'), 'r') as mat:\n",
    "    allresults = mat['/allresults'].value\n",
    "    \n",
    "# this is a huge numpy array now, with dimensions:\n",
    "# 0: run half\n",
    "#        0 = all data\n",
    "#        1 = first half of runs\n",
    "#        2 = second half of runs\n",
    "# 1: subjects (len = 184)\n",
    "# 2: prf param (len = 6)\n",
    "#        0 = polar angle (in degrees from 0-360)\n",
    "#        1 = ecc\n",
    "#        2 = size\n",
    "#        3 = gain\n",
    "#        4 = r2\n",
    "#        5 = mean signal\n",
    "# 3: voxels (len = 91282)\n",
    "\n",
    "ciftidims = {\n",
    "    'polar':0,\n",
    "    'ecc':1,\n",
    "    'size':2,\n",
    "    'gain':3,\n",
    "    'r2':4,\n",
    "    'mean':5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_in_stim_ratio(xs,ys,sigmas):\n",
    "    \"\"\"\n",
    "    computes the ratio of pRF that falls within the stimulus\n",
    "    aperture\n",
    "    \"\"\"\n",
    "    \n",
    "    scope = 4 # times the stimated region\n",
    "    res = 100 # 4*stim_radius * \n",
    "    stim_radius = 8\n",
    "    n = 0.05\n",
    "    \n",
    "    from popeye.spinach import generate_og_receptive_fields\n",
    "\n",
    "    # define visual space in coordinates\n",
    "    deg_x, deg_y                    =   np.meshgrid(np.linspace(-stim_radius*scope, stim_radius*scope, res), np.linspace(-stim_radius*scope, stim_radius*scope, res)) \n",
    "\n",
    "    # create the rfs using the popeye gaussian function\n",
    "    rfs                             =   generate_og_receptive_fields(xs.astype(float),ys.astype(float),sigmas.astype(float),np.ones(len(xs)).astype(float),deg_x.astype(float),deg_y.astype(float))                                    \n",
    "    # apply the non linearity\n",
    "    css_rfs                               =   rfs ** n\n",
    "    # compute the total pRF content\n",
    "    total_prf_content               =   css_rfs.reshape((res**2,-1)).sum(axis=0) \n",
    "    # and the amount of the pRF inside the stim region\n",
    "    stim_vignet                        =   np.sqrt(deg_x ** 2 + deg_y**2) < stim_radius                            \n",
    "    in_stim_ratio                      =   css_rfs[stim_vignet,:].sum(axis=0) / total_prf_content                 \n",
    "    in_stim_ratio[np.isnan(in_stim_ratio)] = 0\n",
    "\n",
    "    return in_stim_ratio, css_rfs, stim_vignet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gmm_threshold(data,n_components=2,maxrange=100):\n",
    "\n",
    "    from sklearn.mixture import GMM\n",
    "\n",
    "    # fit gaussian mixture model to define r2 threshold\n",
    "    gmm = GMM(n_components = n_components)\n",
    "    gmm = gmm.fit(np.expand_dims(data,1))\n",
    "\n",
    "    x = np.linspace(0,maxrange,10000)\n",
    "    logprob, responsibilities = gmm.score_samples(np.expand_dims(x,1))\n",
    "\n",
    "    pdf = np.exp(logprob)\n",
    "    pdf_individual = responsibilities * pdf[:, np.newaxis]\n",
    "\n",
    "    thresh = x[np.where(pdf_individual[:,0]>pdf_individual[:,1])[0]][0]\n",
    "    if thresh == 0:\n",
    "        thresh = x[np.where(pdf_individual[:,1]>pdf_individual[:,0])[0]][0]\n",
    "\n",
    "    return thresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create weighted average subject\n",
    "\n",
    "The HCP dataset contains an average subject, where the timecourses are averaged, to which pRF models are then fit. This seems like an extremely ugly way to average data across subjects. Potentially much nicer is to create a weighted average subject, weighted on R2 of the pRF model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to create average polar angles, we first have to convert to complex numbers:\n",
    "# convert the angle to radians to complex numbers, and scale r2 values to [0,1]\n",
    "rads = 2*np.pi*allresults[:,:,ciftidims['polar'],:]/360\n",
    "real, imag = np.cos(rads) , np.sin(rads) # this ensures that 0 is right\n",
    "newresults = np.array([real, imag, allresults[:,:,0,:], allresults[:,:,1,:], allresults[:,:,2,:], allresults[:,:,3,:], allresults[:,:,4,:], allresults[:,:,5,:]]).transpose((1,2,0,3))\n",
    "newresults_dims = {\n",
    "    'x': 0,\n",
    "    'y': 1,\n",
    "    'polar':2,\n",
    "    'ecc':3,\n",
    "    'size':4,\n",
    "    'gain':5,\n",
    "    'r2':6,\n",
    "    'mean':7\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vanes/anaconda2/envs/analysis/lib/python2.7/site-packages/ipykernel/__main__.py:15: RuntimeWarning: invalid value encountered in less\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2thresh for weighted avg subject:12.971\n"
     ]
    }
   ],
   "source": [
    "# remove voxels from the 'noise' pool in the averaging procedure:\n",
    "weights = copy.copy(newresults[:,:,newresults_dims['r2'],:])\n",
    "weights[weights<2.2] = 0.00001\n",
    "# weights[weights>=2.2] = 100\n",
    "\n",
    "# re-code the data for weighted average subject\n",
    "comp_angle = real + imag * 1j\n",
    "# scale the complex number by the rsq (i.e. applying weight)\n",
    "scaled_comp_angle = comp_angle * weights\n",
    "\n",
    "# now average over subjects, and convert back to radians\n",
    "avg_angle = np.angle(np.mean(scaled_comp_angle, axis=1))[0]\n",
    "# avg_angle = avg_angle / (2*np.pi) * 360\n",
    "# now rescale so it runs from 0-360 again, where 0 is right \n",
    "avg_angle[avg_angle <0] = np.pi*2+avg_angle[avg_angle <0]\n",
    "avg_angle = np.degrees(avg_angle)\n",
    "\n",
    "# average rsq, ecc and size over subjects:\n",
    "# rsq_weights = (weights>=2.2).astype(int)\n",
    "# rsq_weights[rsq_weights==0] = 0.00001\n",
    "\n",
    "# avg_rsq = np.average(weights,weights=rsq_weights, axis=1)[0]\n",
    "\n",
    "avg_rsq = np.average(newresults[:,:,newresults_dims['r2'],:],weights= weights, axis=1)[0]\n",
    "\n",
    "r2thresh = gmm_threshold(np.ravel(avg_rsq))\n",
    "print 'r2thresh for weighted avg subject:%.3f'%r2thresh\n",
    "    \n",
    "avg_ecc = np.average(newresults[:,:,newresults_dims['ecc'],:], axis=1, weights=weights)[0]\n",
    "avg_size = np.average(newresults[:,:,newresults_dims['size'],:], axis=1, weights=weights)[0]\n",
    "avg_gain = np.average(newresults[:,:,newresults_dims['gain'],:], axis=1, weights=weights)[0]\n",
    "avg_meanvol = np.average(newresults[:,:,newresults_dims['mean'],:], axis=1, weights=weights)[0]\n",
    "\n",
    "\n",
    "# avg_ecc = np.median(newresults[:,:,3,:], axis=1)[0]\n",
    "# avg_size = np.median(newresults[:,:,7,:], axis=1)[0]\n",
    "\n",
    "# r2thresh = gmm_threshold(np.ravel(avg_rsq))\n",
    "\n",
    "# eccthresh = gmm_threshold(np.ravel(avg_ecc))\n",
    "\n",
    "# sizethresh = gmm_threshold(np.ravel(avg_size))\n",
    "\n",
    "\n",
    "# print r2thresh, eccthresh, sizethresh\n",
    "# add mask\n",
    "# mask = (avg_rsq > 0.4) # pRFs with too poor r2\n",
    "# mask *= (avg_size > 2) # pRFs larger than 2 degrees\n",
    "# mask *= (avg_ecc > 0.5) # pRFs closer than 0.5 degrees to fixation\n",
    "\n",
    "# apply mask\n",
    "# avg_rsq[~mask] = np.nan\n",
    "# avg_ecc[~mask] = np.nan\n",
    "# avg_size[~mask] = np.nan\n",
    "# avg_angle[~mask] = np.nan\n",
    "\n",
    "# add as 184th subject\n",
    "cii = os.path.join(out_dir,'all_subjects','prfresults_subject_184.dscalar.nii')\n",
    "# print cii\n",
    "cifti.write(cii, [avg_angle, avg_ecc, avg_gain, avg_meanvol,avg_rsq,avg_size], (cifti.Scalar.from_names(['ang', 'ecc', 'gain', 'meanvol','r2','rfsize']), bm))\n",
    "# and convert the created cifti file to gii files\n",
    "wbc_c = wbc.format(cii=cii, cii_n=cii[:-4])\n",
    "os.system(wbc_c);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# now save ciftis niftis and giftis of all subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For all subjects\n",
    "for sj in [45,149]:#range(184):\n",
    "    \n",
    "    # get results for this subject\n",
    "    these_results = copy.copy(allresults[0,sj])\n",
    "    these_results1 = copy.copy(allresults[1,sj])\n",
    "    these_results2 = copy.copy(allresults[2,sj])\n",
    "\n",
    "    # compute euclidean distance between prf centers between run halfs\n",
    "    xs1 = np.cos(np.radians(np.ravel(these_results_1[ciftidims['polar']]))) * np.ravel(these_results_1[ciftidims['ecc']])\n",
    "    ys1 = np.sin(np.radians(np.ravel(these_results_1[ciftidims['polar']]))) * np.ravel(these_results_1[ciftidims['ecc']])\n",
    "\n",
    "    xs2 = np.cos(np.radians(np.ravel(these_results_2[ciftidims['polar']]))) * np.ravel(these_results_2[ciftidims['ecc']])\n",
    "    ys2 = np.sin(np.radians(np.ravel(these_results_2[ciftidims['polar']]))) * np.ravel(these_results_2[ciftidims['ecc']])\n",
    "\n",
    "    diff_vectors = np.array([np.ravel([xs1-xs2]),np.ravel([ys1-ys2])]) \n",
    "    diff_norms = np.linalg.norm(diff_vectors,axis=0)\n",
    "\n",
    "    new_results = np.concatenate([allresults[0,sj],diff_norms[np.newaxis,:]],axis=0)\n",
    "    \n",
    "    # save results\n",
    "    cii = os.path.join(out_dir,'all_subjects','prfresults_subject_%d.dscalar.nii'%sj)\n",
    "    cifti.write(cii, new_results, (cifti.Scalar.from_names(['ang', 'ecc', 'gain', 'meanvol', 'R2', 'rfsize','dist']), bm))\n",
    "    # and convert the created cifti file to gii files\n",
    "    wbc_c = wbc.format(cii=cii, cii_n=cii[:-4])\n",
    "    os.system(wbc_c)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add in stim ratio to niftis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dims = {\n",
    "    'polar':0,\n",
    "    'ecc':1,\n",
    "    'r2':4,\n",
    "    'size':5\n",
    "}\n",
    "\n",
    "# Add in stim ratio to niftis\n",
    "for sj in [45,149]:#range(184):\n",
    "\n",
    "    # load the prf results nifti\n",
    "    fn = os.path.join(out_dir,'all_subjects','prfresults_subject_%d.dscalar_data_sub.nii'%sj)\n",
    "    img = nb.load(fn)\n",
    "    data = img.get_data()\n",
    "\n",
    "    # compute in stim ratio\n",
    "    xs = np.cos(np.radians(np.ravel(data[:,:,:,dims['polar']]))) * np.ravel(data[:,:,:,dims['ecc']])\n",
    "    ys = np.sin(np.radians(np.ravel(data[:,:,:,dims['polar']]))) * np.ravel(data[:,:,:,dims['ecc']])\n",
    "    \n",
    "    sizes = data[:,:,:,dims['size']]\n",
    "    v = (np.ravel(sizes)>0)\n",
    "\n",
    "    in_stim_ratio = compute_in_stim_ratio(xs[v],ys[v],np.ravel(sizes)[v])[0]\n",
    "    all_in_stim_ratios = np.zeros(np.shape(sizes))\n",
    "    all_v = (sizes>0)\n",
    "    all_in_stim_ratios[all_v] = in_stim_ratio\n",
    "    \n",
    "    data = np.concatenate([data,all_in_stim_ratios[:,:,:,np.newaxis]],axis=3)\n",
    "\n",
    "    # save data (overwrite previous nifti, as its not changing the other dimensions)\n",
    "    out_fn = os.path.join(out_dir,'all_subjects','prfresults_subject_%d.dscalar_data_sub.nii'%sj)        \n",
    "    new_data = nb.Nifti1Image(data,affine=img.affine,header=img.header)\n",
    "    nb.save(new_data,out_fn)\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [analysis]",
   "language": "python",
   "name": "Python [analysis]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
