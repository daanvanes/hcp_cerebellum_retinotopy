{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures\n",
    "\n",
    "This notebook creates the following figures:\n",
    "\n",
    "* visual field coverage plots\n",
    "* polar angle histograms\n",
    "* eccentricity distributions\n",
    "* eccentricity-size relations\n",
    "* timeseries plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "from __future__ import division\n",
    "import os\n",
    "import nibabel as nb\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import h5py\n",
    "import matplotlib.pyplot as pl\n",
    "import seaborn as sn\n",
    "sn.set_style('ticks')\n",
    "import glob\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "mpl.rc_file_defaults()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define directories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set this to your data directory:\n",
    "data_dir = '/home/shared/2018/visual/hcp_cerebellum/'\n",
    "repo_dir = '/home/vanes/git/hcp_cerebellum/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### subdirectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resource_dir = os.path.join(repo_dir,'resources')\n",
    "retmap_dir = os.path.join(resource_dir,'volume_masks')\n",
    "\n",
    "# setup figure directory\n",
    "fig_dir = os.path.join(data_dir,'figs')\n",
    "if not os.path.isdir(fig_dir): os.mkdir(fig_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# these are the dimensions of the niftis\n",
    "dims = {\n",
    "    'ang':0,\n",
    "    'ecc':1,\n",
    "    'gain':2,\n",
    "    'meanvol':3,\n",
    "    'r2':4,\n",
    "    'rfsize':5\n",
    "}   \n",
    "\n",
    "stim_radius = 8\n",
    "avg_masktype = 'r2_spill_fix'\n",
    "ind_masktype = 'r2_roi'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define rois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# these refer to the indices in cerebellum_retmaps.nii\n",
    "mask_names ={\n",
    "'left_mOMV':7,\n",
    "'right_mOMV':9,\n",
    "'left_lOMV':8,\n",
    "'right_lOMV':10,\n",
    "    \n",
    "'left_VIIb':5,\n",
    "'right_VIIb':6,\n",
    "    \n",
    "'left_mVIIIb':3,\n",
    "'right_mVIIIb':2,\n",
    "'left_lVIIIb':4,\n",
    "'right_lVIIIb':1,\n",
    "}\n",
    "\n",
    "# this is how the lateral/medial and left right hemisphere indices combine:\n",
    "roi_combs = {\n",
    "    'left_OMV':[7,8],\n",
    "    'right_OMV':[9,10],\n",
    "    'left_VIIb':[5],\n",
    "    'right_VIIb':[6],\n",
    "    'left_VIIIb':[3,4],\n",
    "    'right_VIIIb':[1,2],\n",
    "\n",
    "    'OMV':[7,8,9,10],\n",
    "    'lOMV':[8,10],\n",
    "    'mOMV':[7,9],\n",
    "    'VIIb':[5,6],\n",
    "    'VIIIb':[1,2,3,4],\n",
    "    'lVIIIb':[1,4],\n",
    "    'mVIIIb':[2,3],\n",
    "}\n",
    "\n",
    "roi_order = ['left_mOMV','right_mOMV','left_lOMV','right_lOMV','left_VIIb','right_VIIb','left_mVIIIb','right_mVIIIb','left_lVIIIb','right_lVIIIb']\n",
    "roi_comb_order = ['mOMV','lOMV','VIIb','mVIIIb','lVIIIb']           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get the data\n",
    "avgdata = nb.load(os.path.join(base_dir,'masked_niftis','r2_spill_fix','prfresults_subject_rank_avg.nii.gz')).get_data()\n",
    "cer_retmaps = nb.load(os.path.join(retmap_dir,'cerebellum_retmaps.nii')).get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### function for determining roi color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_roi_color(mask):\n",
    "    \n",
    "    # determine base roi colors\n",
    "    if mask in ['left_OMV','right_OMV','OMV']:\n",
    "        c = '#6590CB'\n",
    "    elif mask in ['left_VIIIb','right_VIIIb','VIIIb']:\n",
    "        c = '#E55D5C'\n",
    "    elif ('VIIb' in mask) + (mask=='VIIb'):\n",
    "        c = '#E79F2A'\n",
    "        \n",
    "    # roi colors for lateral / medial separation:\n",
    "    elif mask in ['left_lOMV','right_lOMV','lOMV']:\n",
    "        c = '#6590CB'\n",
    "    elif mask in ['left_mOMV','right_mOMV','mOMV']:\n",
    "        c = '#0D5B99'\n",
    "    elif mask in ['left_mVIIIb','right_mVIIIb','mVIIIb']:\n",
    "        c = '#C03142'\n",
    "    elif mask in ['left_lVIIIb','right_lVIIIb','lVIIIb']:\n",
    "        c = '#E57F80'\n",
    "        \n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualize pRF center + size distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = pl.figure(figsize=(2,4.5))\n",
    "for mi,mask in enumerate(roi_order):\n",
    "    \n",
    "    s = f.add_subplot(5,2,mi+1,aspect='equal')\n",
    "\n",
    "    # determine this roi mask\n",
    "    roimask = (cer_retmaps==(mask_names[mask]))\n",
    "\n",
    "    # convert polar to cartesian:\n",
    "    xs = np.cos(np.radians(np.ravel(avgdata[roimask,dims['ang']]))) * np.ravel(avgdata[roimask,dims['ecc']])\n",
    "    ys = np.sin(np.radians(np.ravel(avgdata[roimask,dims['ang']]))) * np.ravel(avgdata[roimask,dims['ecc']])\n",
    "\n",
    "    # get sizes\n",
    "    sizes = np.ravel(avgdata[roimask,dims['rfsize']])\n",
    "\n",
    "    # determine roi color\n",
    "    c = get_roi_color(mask)\n",
    "\n",
    "    # now draw a circle at rf size\n",
    "    for x,y,sigma in zip(xs,ys,sizes):\n",
    "        s.add_artist(pl.Circle((x,y),sigma, color=c,fill=False,alpha=0.25))\n",
    "\n",
    "    # draw crosshair\n",
    "    pl.axhline(0,lw=0.5,color='k')\n",
    "    pl.axvline(0,lw=0.5,color='k')\n",
    "\n",
    "    # draw dot at center \n",
    "    pl.plot(xs,ys,'o',color=c,ms=3,mec='w',mew=1,alpha=1)\n",
    "    pl.xlim(-stim_radius,stim_radius)\n",
    "    pl.ylim(-stim_radius,stim_radius)   \n",
    "\n",
    "    # only draw the axis labels for VIIIb:\n",
    "    if mask =='left_lVIIIb':\n",
    "        pl.xticks([-stim_radius,0,stim_radius],['-%d'%stim_radius,0,'%.d'%stim_radius])\n",
    "        pl.yticks([-stim_radius,0,stim_radius],['-%d'%stim_radius,0,'%.d'%stim_radius])\n",
    "        sn.despine(offset=2)\n",
    "    elif mask =='right_lVIIIb':\n",
    "        pl.xticks([-stim_radius,0,stim_radius],['-%.d'%stim_radius,0,'%.d'%stim_radius])\n",
    "        pl.yticks([])\n",
    "        sn.despine(offset=2,left=True)\n",
    "    else:\n",
    "        pl.axis('off')\n",
    "        pl.xticks([])\n",
    "        pl.yticks([])                \n",
    "\n",
    "pl.tight_layout()\n",
    "f.savefig(os.path.join(fig_dir,'prf_scatter_avg_subject.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create eccentricity-size plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# eccen-size plot\n",
    "this_roi_comb_order = ['mVIIIb','lVIIIb','VIIb','mOMV','lOMV']\n",
    "\n",
    "f = pl.figure(figsize=(1.25,1.25))\n",
    "s = f.add_subplot(111)\n",
    "\n",
    "all_max_eccs = []\n",
    "all_max_sizes=[]\n",
    "for mi,mask in enumerate(this_roi_comb_order):\n",
    "\n",
    "    # determine this roi mask\n",
    "    roimask = np.zeros_like(cer_retmaps).astype(bool)\n",
    "    for subroi in roi_combs[mask]:\n",
    "        roimask[(cer_retmaps==subroi)] = True\n",
    "\n",
    "    # determine roi color\n",
    "    c = get_roi_color(mask)  \n",
    "\n",
    "    sizes = np.ravel(avgdata[roimask,dims['rfsize']])\n",
    "    eccs = np.ravel(avgdata[roimask,dims['ecc']])\n",
    "\n",
    "    maxecc = np.min([np.nanmax(eccs),stim_radius])\n",
    "\n",
    "    v = (eccs < maxecc)\n",
    "\n",
    "    # do linear regression with statsmodels\n",
    "    y = sizes[v]\n",
    "    X = eccs[v]\n",
    "    X = sm.add_constant(X)     \n",
    "\n",
    "    mod = sm.OLS(y, X)\n",
    "    res = mod.fit()\n",
    "    ci_intercept,ci_slope = res.conf_int(0.05)\n",
    "    mean_intercept,mean_slope = res.params\n",
    "\n",
    "    fit = np.polyval([mean_slope,mean_intercept],np.linspace(0,maxecc,15))\n",
    "    fit_high = np.polyval([ci_slope[0],ci_intercept[1]],np.linspace(0,maxecc,15))\n",
    "    fit_low = np.polyval([ci_slope[1],ci_intercept[0]],np.linspace(0,maxecc,15))\n",
    "\n",
    "    pl.plot(np.linspace(0,maxecc,15),fit,color=c,lw=2)\n",
    "    pl.fill_between(np.linspace(0,maxecc,15),fit_low,fit_high,alpha=0.25,color=c)\n",
    "\n",
    "pl.xlim(0,stim_radius)  \n",
    "pl.ylim(0,10)\n",
    "pl.xticks([0,stim_radius])\n",
    "pl.yticks([0,10])\n",
    "\n",
    "sn.despine(offset=2)\n",
    "\n",
    "pl.tight_layout()\n",
    "f.savefig(os.path.join(fig_dir,'prf_eccsize_avg.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create eccentricity histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = pl.figure(figsize=(1.25,2))\n",
    "s = f.add_subplot(111)\n",
    "\n",
    "dc = pd.DataFrame()\n",
    "colors = []\n",
    "\n",
    "for mi,mask in enumerate(roi_comb_order):\n",
    "\n",
    "    # determine this roi mask\n",
    "    roimask = np.zeros_like(cer_retmaps).astype(bool)\n",
    "    for subroi in roi_combs[mask]:\n",
    "        roimask[(cer_retmaps==subroi)] = True\n",
    "\n",
    "    # get data\n",
    "    eccs = np.ravel(avgdata[roimask,dims['ecc']])\n",
    "\n",
    "    # get roi color and append to all\n",
    "    c = get_roi_color(mask)\n",
    "    colors.append(c)\n",
    "    \n",
    "    # get eccentricities, append with nans (otherwise df is shortened to roi with least voxels)\n",
    "    dc[mask] = np.hstack([eccs,np.ones(100000-len(eccs))*np.nan])\n",
    "\n",
    "sn.violinplot(data=dc,palette=colors,scale='width',orient='h',linewidth=0)\n",
    "\n",
    "pl.xlim(0,stim_radius)\n",
    "pl.xticks([0,stim_radius])\n",
    "sn.despine(offset=2)\n",
    "pl.xlabel('eccen (dva)')\n",
    "\n",
    "pl.tight_layout(pad=0)\n",
    "f.savefig(os.path.join(fig_dir,'ecc_histograms_avg.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### polar histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for hemi in ['left','right']:\n",
    "    f = pl.figure(figsize=(0.75,4.5))\n",
    "\n",
    "    for mi,roi in enumerate(['mOMV','lOMV','VIIb','mVIIIb','lVIIIb']):\n",
    "        mask = hemi+'_'+roi\n",
    "        s = f.add_subplot(5,1,mi+1,projection='polar')\n",
    "\n",
    "        # determine this roi mask\n",
    "        roimask = (cer_retmaps==(mask_names[mask]))\n",
    "\n",
    "        # determine color for this ROI\n",
    "        c = get_roi_color(mask)\n",
    "\n",
    "        # get data (convert to radians for polar plot)\n",
    "        angles = np.radians(np.ravel(avgdata[roimask,dims['ang']]))\n",
    "\n",
    "        # compute bins (let's do for 12 bins)\n",
    "        bins_number = 12\n",
    "        bins = np.linspace(0.0, 2 * np.pi, bins_number + 1)\n",
    "        n, _, _ = pl.hist(angles, bins)\n",
    "        width = (2 * np.pi) / bins_number\n",
    "        \n",
    "        # plot polar bars\n",
    "        s.cla()        \n",
    "        pl.bar(bins[:bins_number], n, width=width, bottom=0.0,ec=c,color=c)\n",
    "\n",
    "        # plot settings\n",
    "        pl.xticks([])\n",
    "        pl.yticks([])\n",
    "        pl.ylim(0,np.max(n))\n",
    "\n",
    "    pl.tight_layout()\n",
    "    f.savefig(os.path.join(fig_dir,'polar_histograms_avg_%s.pdf'%(hemi)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### individual subject eccen-size relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could not fit mOMV ecc-size relation for mid subject 89 (too little data)\n",
      "could not fit lVIIIb ecc-size relation for mid subject 88 (too little data)\n",
      "could not fit lVIIIb ecc-size relation for mid subject 90 (too little data)\n",
      "could not fit lVIIIb ecc-size relation for mid subject 91 (too little data)\n",
      "could not fit mOMV ecc-size relation for bottom subject 176 (too little data)\n",
      "could not fit mOMV ecc-size relation for bottom subject 177 (too little data)\n",
      "could not fit mOMV ecc-size relation for bottom subject 178 (too little data)\n",
      "could not fit mOMV ecc-size relation for bottom subject 179 (too little data)\n",
      "could not fit mOMV ecc-size relation for bottom subject 180 (too little data)\n",
      "could not fit lOMV ecc-size relation for bottom subject 176 (too little data)\n",
      "could not fit lOMV ecc-size relation for bottom subject 177 (too little data)\n",
      "could not fit lOMV ecc-size relation for bottom subject 178 (too little data)\n",
      "could not fit lOMV ecc-size relation for bottom subject 179 (too little data)\n",
      "could not fit lOMV ecc-size relation for bottom subject 180 (too little data)\n",
      "could not fit VIIb ecc-size relation for bottom subject 176 (too little data)\n",
      "could not fit VIIb ecc-size relation for bottom subject 177 (too little data)\n",
      "could not fit VIIb ecc-size relation for bottom subject 179 (too little data)\n",
      "could not fit VIIb ecc-size relation for bottom subject 180 (too little data)\n",
      "could not fit mVIIIb ecc-size relation for bottom subject 177 (too little data)\n",
      "could not fit mVIIIb ecc-size relation for bottom subject 179 (too little data)\n",
      "could not fit mVIIIb ecc-size relation for bottom subject 180 (too little data)\n",
      "could not fit lVIIIb ecc-size relation for bottom subject 176 (too little data)\n",
      "could not fit lVIIIb ecc-size relation for bottom subject 177 (too little data)\n",
      "could not fit lVIIIb ecc-size relation for bottom subject 178 (too little data)\n",
      "could not fit lVIIIb ecc-size relation for bottom subject 179 (too little data)\n",
      "could not fit lVIIIb ecc-size relation for bottom subject 180 (too little data)\n"
     ]
    }
   ],
   "source": [
    "# eccen-size plot\n",
    "for sgi,sjg in zip([range(5),range(88,93),range(176,181)],['top','mid','bottom']):\n",
    "    \n",
    "    f = pl.figure(figsize=(0.75*5,0.75))\n",
    "    for mi,mask in enumerate(roi_comb_order):\n",
    "        s = f.add_subplot(1,len(roi_comb_order),mi+1)\n",
    "\n",
    "        # determine this roi mask\n",
    "        roimask = np.zeros_like(cer_retmaps).astype(bool)\n",
    "        for subroi in roi_combs[mask]:\n",
    "            roimask[(cer_retmaps==subroi)] = True\n",
    "\n",
    "        # determine ecc limit and roi color\n",
    "        c = get_roi_color(mask)  \n",
    "\n",
    "        for sj in sgi:\n",
    "            \n",
    "            this_sj_data = nb.load(os.path.join(data_dir,'masked_niftis','r2_roi','prfresults_subject_rank_%d.nii.gz'%sj)).get_data()\n",
    "\n",
    "            try:                \n",
    "                sizes = np.ravel(this_sj_data[roimask,dims['rfsize']])\n",
    "                eccs = np.ravel(this_sj_data[roimask,dims['ecc']])                \n",
    "                \n",
    "                # determine valid voxels\n",
    "                maxecc = np.min([np.nanmax(eccs),stim_radius])\n",
    "                v = (eccs < maxecc)\n",
    "\n",
    "                # do linear regression with statsmodels\n",
    "                y = sizes[v]\n",
    "                X = eccs[v]\n",
    "                X = sm.add_constant(X)     \n",
    "\n",
    "\n",
    "                mod = sm.OLS(y, X)\n",
    "                res = mod.fit()\n",
    "                ci_intercept,ci_slope = res.conf_int(0.05)\n",
    "                mean_intercept,mean_slope = res.params\n",
    "\n",
    "                fit = np.polyval([mean_slope,mean_intercept],np.linspace(0,maxecc,15))\n",
    "                fit_high = np.polyval([ci_slope[0],ci_intercept[1]],np.linspace(0,maxecc,15))\n",
    "                fit_low = np.polyval([ci_slope[1],ci_intercept[0]],np.linspace(0,maxecc,15))\n",
    "\n",
    "                pl.plot(np.linspace(0,maxecc,15),fit,color=c,lw=1)\n",
    "                pl.fill_between(np.linspace(0,maxecc,15),fit_low,fit_high,alpha=0.25,color=c)\n",
    "                \n",
    "            except:\n",
    "                print 'could not fit %s ecc-size relation for %s subject %d (too little data)'%(mask,sjg,sj)\n",
    "\n",
    "\n",
    "        pl.xlim(0,stim_radius)  \n",
    "        pl.ylim(0,10)\n",
    "        pl.xticks([0,stim_radius])\n",
    "        pl.yticks([0,10])\n",
    "\n",
    "        sn.despine(offset=2)\n",
    "\n",
    "    pl.tight_layout()\n",
    "    f.savefig(os.path.join(fig_dir,'prf_eccsize_all_%s.pdf'%(sjg)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Timeseries plot\n",
    "\n",
    "In this plot, we'll get the design matrix from the osf website, and use the pRF model that was fit on all data (wedges / rings / bars) to create a predicted fit for the average of the two bar runs (downloaded in notebook 1_export_ciftis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Popeye imports\n",
    "import popeye.utilities as utils\n",
    "from popeye.visual_stimulus import VisualStimulus\n",
    "import popeye.css as css\n",
    "import scipy as sp\n",
    "import urllib\n",
    "import zipfile\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ap_dir = os.path.join(base_dir,'apertures.zip')\n",
    "ap_url = 'https://osf.io/5sj3m/download'\n",
    "up_ap_dir = os.path.join(base_dir,'apertures')\n",
    "mat_dir = os.path.join(base_dir,'RETBARsmall.mat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### download the design matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading retinotopy design matrices...\n",
      "downloading done!\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isfile(ap_dir):\n",
    "    print('Downloading retinotopy design matrices...')\n",
    "    urllib.urlretrieve(ap_url, ap_dir)  \n",
    "    print('downloading done!')\n",
    "else:\n",
    "    print('dms already downloaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unpacking the dms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dms already unpacked\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isdir(up_ap_dir):\n",
    "    print('unpacking dms')\n",
    "    zip_ref = zipfile.ZipFile(ap_dir, 'r')\n",
    "    zip_ref.extractall(ap_dir[:-4])\n",
    "    zip_ref.close()\n",
    "    # remove zip file\n",
    "    os.remove(ap_dir)\n",
    "else:\n",
    "    print('dms already unpacked')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### move and remove files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dm ret file already moved\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isfile(mat_dir):\n",
    "    os.rename(os.path.join(up_ap_dir,'apertures','RETBARsmall.mat'),mat_dir)\n",
    "    shutil.rmtree(up_ap_dir)\n",
    "else:\n",
    "    print('dm ret file already moved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now load in file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with h5py.File(mat_dir, 'r') as mat:\n",
    "    visual_dm = mat['stim'].value.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert file to popey visual stimulus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create stimulus design and define model\n",
    "# ---------------------------------------\n",
    "stimulus = VisualStimulus(  stim_arr = visual_dm,\n",
    "                            viewing_distance = 102, \n",
    "                            screen_width = 29,\n",
    "                            scale_factor = 1,\n",
    "                            tr_length = 1.0,\n",
    "                            dtype = np.short)\n",
    "\n",
    "model_func = css.CompressiveSpatialSummationModel(  stimulus = stimulus,\n",
    "                                                    hrf_model = utils.spm_hrf)\n",
    "model_func.hrf_delay = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load in the averaged timecourse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get timeseries data\n",
    "# ---------------------------------------\n",
    "timeseries_fn = os.path.join(base_dir,'timeseries','avg_prf_timeseries.nii.gz')\n",
    "timeseries_data = nb.load(timeseries_fn).get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# zscore timeseries\n",
    "avg = np.nanmean(timeseries_data,axis=-1)[:,:,:,np.newaxis]\n",
    "std = np.nanstd(timeseries_data,axis=-1)[:,:,:,np.newaxis]\n",
    "timeseries_data = (timeseries_data-avg)/std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setup function that creates prediction and rescales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_prediction(voxel_idx,roimask):\n",
    "\n",
    "    # get prf parameters\n",
    "    ang = np.radians(avgdata[roimask,dims['ang']][voxel_idx])\n",
    "    ecc = avgdata[roimask,dims['ecc']][voxel_idx]\n",
    "    size = avgdata[roimask,dims['rfsize']][voxel_idx]\n",
    "\n",
    "    # get ts data\n",
    "    these_ts = timeseries_data[roimask]\n",
    "    \n",
    "    # convert to cartesian\n",
    "    x = ecc * np.cos(ang)\n",
    "    y = ecc * np.sin(ang)\n",
    "\n",
    "    # this is the n used in the paper\n",
    "    n = 0.05\n",
    "\n",
    "    # calculate prediction\n",
    "    pred = model_func.generate_prediction(x,y,size,n,1,0)\n",
    "    \n",
    "    # refit baseline and amp parameters (since fitted on different data)\n",
    "    dm = np.mat(np.vstack([np.ones_like(pred),pred])).T\n",
    "    t = these_ts[voxel_idx]\n",
    "    intercept,slope = np.array(np.linalg.pinv(dm.T * dm) * dm.T * np.mat(t[:,np.newaxis]))     \n",
    "\n",
    "    # scale prediction\n",
    "    p =(intercept[0]+pred*slope[0])\n",
    "\n",
    "    # compute new r2\n",
    "    r2 = (sp.stats.pearsonr(p,t)[0]**2)*100\n",
    "    \n",
    "    return p,r2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine best voxels for these data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating predictions for ecc_band [0, 2], mask mOMV, 0%done\n",
      "creating predictions for ecc_band [0, 2], mask lOMV, 0%done\n",
      "creating predictions for ecc_band [0, 2], mask lOMV, 20%done\n",
      "creating predictions for ecc_band [0, 2], mask lOMV, 40%done\n",
      "creating predictions for ecc_band [0, 2], mask lOMV, 60%done\n",
      "creating predictions for ecc_band [0, 2], mask lOMV, 80%done\n",
      "creating predictions for ecc_band [0, 2], mask VIIb, 0%done\n",
      "creating predictions for ecc_band [0, 2], mask mVIIIb, 0%done\n",
      "creating predictions for ecc_band [0, 2], mask mVIIIb, 20%done\n",
      "creating predictions for ecc_band [0, 2], mask mVIIIb, 40%done\n",
      "creating predictions for ecc_band [0, 2], mask mVIIIb, 60%done\n",
      "creating predictions for ecc_band [0, 2], mask mVIIIb, 80%done\n",
      "creating predictions for ecc_band [0, 2], mask lVIIIb, 0%done\n",
      "creating predictions for ecc_band [2, 4], mask VIIb, 0%done\n",
      "creating predictions for ecc_band [2, 4], mask mVIIIb, 0%done\n",
      "creating predictions for ecc_band [2, 4], mask lVIIIb, 0%done\n",
      "creating predictions for ecc_band [4, 6], mask VIIb, 0%done\n",
      "creating predictions for ecc_band [4, 6], mask mVIIIb, 0%done\n",
      "creating predictions for ecc_band [4, 6], mask lVIIIb, 0%done\n",
      "creating predictions for ecc_band [4, 6], mask lVIIIb, 20%done\n",
      "creating predictions for ecc_band [4, 6], mask lVIIIb, 40%done\n",
      "creating predictions for ecc_band [4, 6], mask lVIIIb, 60%done\n",
      "creating predictions for ecc_band [4, 6], mask lVIIIb, 80%done\n",
      "creating predictions for ecc_band [6, 8], mask mVIIIb, 0%done\n",
      "creating predictions for ecc_band [6, 8], mask lVIIIb, 0%done\n"
     ]
    }
   ],
   "source": [
    "these_r2s = {}\n",
    "ecc_bands = [[0,2],[2,4],[4,6],[6,8]]\n",
    "for ecc_band in ecc_bands:\n",
    "    these_r2s[str(ecc_band)] = {}\n",
    "    \n",
    "    # select data from this ecc band\n",
    "    eccs = avgdata[:,:,:,dims['ecc']]\n",
    "    valid_eccs = (eccs>ecc_band[0])*(eccs<ecc_band[1])\n",
    "    \n",
    "    for mi,mask in enumerate(roi_comb_order):\n",
    "        print('creating predictions for ecc_band %s, mask %s'%(ecc_band,mask))\n",
    "        # determine this roi mask\n",
    "        roimask = np.zeros_like(cer_retmaps).astype(bool)\n",
    "        for subroi in roi_combs[mask]:\n",
    "            roimask[(cer_retmaps==subroi)] = True\n",
    "\n",
    "        roimask *= valid_eccs\n",
    "\n",
    "        # apply mask to timeseries\n",
    "        these_ts = timeseries_data[roimask]\n",
    "    \n",
    "        # now create a prediction for every voxel\n",
    "        # on the averaged data and save the r2s\n",
    "        r2s = []\n",
    "        for v in range(roimask.sum()):\n",
    "\n",
    "            p,r2 = create_prediction(v,roimask)\n",
    "\n",
    "            # recompute r2 on this prediction and data\n",
    "            r2s.append(r2)\n",
    "            \n",
    "        these_r2s[str(ecc_band)][mask] = r2s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### now we can create plot for the best voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create plot\n",
    "# ---------------------------------------\n",
    "n_vox = 5\n",
    "for ecc_band in ecc_bands:\n",
    "    \n",
    "    # select data from this ecc band\n",
    "    eccs = avgdata[:,:,:,dims['ecc']]\n",
    "    valid_eccs = (eccs>ecc_band[0])*(eccs<ecc_band[1])   \n",
    "    \n",
    "    for mi,mask in enumerate(roi_comb_order):\n",
    "\n",
    "        # determine this roi mask\n",
    "        roimask = np.zeros_like(cer_retmaps).astype(bool)\n",
    "        for subroi in roi_combs[mask]:\n",
    "            roimask[(cer_retmaps==subroi)] = True\n",
    "\n",
    "        roimask *= valid_eccs\n",
    "\n",
    "        # apply mask to timeseries\n",
    "        these_ts = timeseries_data[roimask]\n",
    "\n",
    "        # now determine best voxel based on fits to this data\n",
    "        r2s = these_r2s[str(ecc_band)][mask]\n",
    "        best_voxels = np.argsort(r2s)[::-1][:n_vox]\n",
    "\n",
    "        # and create plots for these voxels\n",
    "        for best_voxel in best_voxels:\n",
    "\n",
    "            # get this timeseries\n",
    "            timeseries = these_ts[best_voxel]\n",
    "\n",
    "            pred,r2 = create_prediction(best_voxel,roimask)\n",
    "            \n",
    "            # generate pRF\n",
    "            res = 501\n",
    "\n",
    "            # get pRF parameters for visualization\n",
    "            ang = np.radians(avgdata[roimask,dims['ang']][best_voxel])\n",
    "            ecc = avgdata[roimask,dims['ecc']][best_voxel]\n",
    "            size = avgdata[roimask,dims['rfsize']][best_voxel]\n",
    "            \n",
    "            x = ecc * np.cos(ang)\n",
    "            y = ecc * np.sin(ang)\n",
    "\n",
    "            f=pl.figure(figsize=(4,1.25))            \n",
    "            \n",
    "            # first plot the prf parameters\n",
    "            s = f.add_subplot(141)\n",
    "            pl.text(0,0,'ecc: %.2f\\nangle: %.2f\\nsize: %.2f\\nR2: %.2f'%(ecc,ang,size,r2),\n",
    "                    horizontalalignment='right',verticalalignment='center')            \n",
    "            pl.xlim(-5,5)\n",
    "            pl.ylim(-5,5)\n",
    "            pl.axis('off')\n",
    "            \n",
    "        \n",
    "            # now create a pRF visualization plot\n",
    "            s = f.add_subplot(142,aspect='equal')\n",
    "\n",
    "            c = get_roi_color(mask)\n",
    "\n",
    "            # crosshair\n",
    "            pl.axhline(0,lw=0.5,color='k')\n",
    "            pl.axvline(0,lw=0.5,color='k')\n",
    "            \n",
    "            # for prf size\n",
    "            s.add_artist(pl.Circle((x,y),size, color='r',fill=False,alpha=0.25))\n",
    "            # prf center\n",
    "            pl.plot(x,y,'o',color='r',ms=3,mec='w',mew=1,alpha=1)\n",
    "\n",
    "            # plot properties\n",
    "            pl.xlim(-stim_radius,stim_radius)\n",
    "            pl.ylim(-stim_radius,stim_radius) \n",
    "            pl.xticks([-stim_radius,0,stim_radius])\n",
    "            pl.yticks([-stim_radius,0,stim_radius])\n",
    "            pl.xlabel('visual field x (dva)')\n",
    "            pl.ylabel('visual field y (dva)')\n",
    "            sn.despine(offset=2)\n",
    "            \n",
    "            # and finally the pRF timeseries prediction\n",
    "            s = f.add_subplot(122)\n",
    "    \n",
    "            # timeseries\n",
    "            pl.plot(timeseries,'o--',color='k',ms=1.5)\n",
    "            # prediction\n",
    "            pl.plot(pred,color='r',lw=1.5)\n",
    "\n",
    "            # this is the gray/white shading to indicate stimulus design\n",
    "            ylims=s.get_ylim()\n",
    "            pl.fill_between([0,16],[ylims[0],ylims[0]],[ylims[1],ylims[1]],color='w')\n",
    "            pl.fill_between([16,48],[ylims[0],ylims[0]],[ylims[1],ylims[1]],color='k',alpha=0.1)\n",
    "            pl.fill_between([48,80],[ylims[0],ylims[0]],[ylims[1],ylims[1]],color='w')\n",
    "            pl.fill_between([80,112],[ylims[0],ylims[0]],[ylims[1],ylims[1]],color='k',alpha=0.1)\n",
    "            pl.fill_between([112,144],[ylims[0],ylims[0]],[ylims[1],ylims[1]],color='w')\n",
    "            pl.fill_between([144,156],[ylims[0],ylims[0]],[ylims[1],ylims[1]],color='k',alpha=0.1)\n",
    "            pl.fill_between([156,188],[ylims[0],ylims[0]],[ylims[1],ylims[1]],color='w')\n",
    "            pl.fill_between([188,220],[ylims[0],ylims[0]],[ylims[1],ylims[1]],color='k',alpha=0.1)\n",
    "            pl.fill_between([220,252],[ylims[0],ylims[0]],[ylims[1],ylims[1]],color='w')\n",
    "            pl.fill_between([252,284],[ylims[0],ylims[0]],[ylims[1],ylims[1]],color='k',alpha=0.1) \n",
    "            pl.fill_between([284,300],[ylims[0],ylims[0]],[ylims[1],ylims[1]],color='w')             \n",
    "                \n",
    "            # plot properties\n",
    "            sn.despine(offset=2)\n",
    "            pl.xlabel('time (s)')\n",
    "            pl.ylabel('BOLD (z-score)')\n",
    "\n",
    "            # save figure\n",
    "            pl.tight_layout()\n",
    "            f.savefig(os.path.join(fig_dir,'pred_%s_eccband_%s_v_%d.pdf'%(mask,ecc_band,best_voxel)))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [analysis]",
   "language": "python",
   "name": "Python [analysis]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
