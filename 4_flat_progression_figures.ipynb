{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flatmap data\n",
    "\n",
    "This notebook creates plots of the polar and eccentricity data that was projected to the flatmap by the SUIT toolbox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pycircstat as pc\n",
    "import copy as copy\n",
    "import os\n",
    "import nibabel as nb\n",
    "import statsmodels.stats.api as sms\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as pl\n",
    "import seaborn as sn\n",
    "sn.set_style('ticks')\n",
    "import glob\n",
    "\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "mpl.rc_file_defaults()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define directories\n",
    "data_dir = '/home/shared/2018/visual/hcp_cerebellum/'\n",
    "repo_dir  = '/home/vanes/git/hcp_cerebellum/'\n",
    "suit_home  = '/home/vanes/bin/suit/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### subdirectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resource_dir = os.path.join(repo_dir,'resources')\n",
    "flat_dir = os.path.join(data_dir,'flat_data')\n",
    "\n",
    "# setup figure directory\n",
    "fig_dir = os.path.join(data_dir,'figs')\n",
    "if not os.path.isdir(fig_dir): os.mkdir(fig_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# these are the coordinates of the SUIT flat data:\n",
    "# in the toolbox, these are located in $spmhome/suit/flatmap\n",
    "coords=nb.load(os.path.join(suit_home,'flatmap','FLAT.coord.gii'))\n",
    "\n",
    "x = np.ravel(coords.get_arrays_from_intent(1008)[0].data[:,0]) \n",
    "y = np.ravel(coords.get_arrays_from_intent(1008)[0].data[:,1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get the flatmap representations of the retmaps\n",
    "masks=np.ravel(pd.read_csv(os.path.join(flat_dir,'retmaps_flat.csv'),header=None))\n",
    "sjs = ['181','181_1','181_2','182','182_1','182_2','183','183_1','183_2']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "roi_order = ['left_OMV','right_OMV','left_VIIb','right_VIIb','left_VIIIb','right_VIIIb']\n",
    "\n",
    "these_combs = {\n",
    "    'left_OMV':['left_mOMV','left_lOMV'],\n",
    "    'right_OMV':['right_mOMV','right_lOMV'],\n",
    "    'left_VIIb':['left_VIIb'],\n",
    "    'right_VIIb':['right_VIIb'],\n",
    "    'left_VIIIb':['left_mVIIIb','left_lVIIIb'],\n",
    "    'right_VIIIb':['right_mVIIIb','right_lVIIIb'],    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rotate_via_numpy(x,y, radians):\n",
    "    \"\"\"Use numpy to build a rotation matrix and take the dot product.\"\"\"\n",
    "    c, s = np.cos(radians), np.sin(radians)\n",
    "    j = np.matrix([[c, s], [-s, c]])\n",
    "    m = np.dot(j, np.matrix([x, y]))\n",
    "\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_roi_color(mask):\n",
    "    \n",
    "    # determine base roi colors\n",
    "    if mask in ['left_OMV','right_OMV','OMV']:\n",
    "        c = '#6590CB'\n",
    "    elif mask in ['left_VIIIb','right_VIIIb','VIIIb']:\n",
    "        c = '#E55D5C'\n",
    "    elif ('VIIb' in mask) + (mask=='VIIb'):\n",
    "        c = '#E79F2A'\n",
    "        \n",
    "    # roi colors for lateral / medial separation:\n",
    "    elif mask in ['left_lOMV','right_lOMV','lOMV']:\n",
    "        c = '#6590CB'\n",
    "    elif mask in ['left_mOMV','right_mOMV','mOMV']:\n",
    "        c = '#0D5B99'\n",
    "    elif mask in ['left_mVIIIb','right_mVIIIb','mVIIIb']:\n",
    "        c = '#C03142'\n",
    "    elif mask in ['left_lVIIIb','right_lVIIIb','lVIIIb']:\n",
    "        c = '#E57F80'\n",
    "        \n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# these refer to the indices in cerebellum_retmaps.nii\n",
    "mask_names ={\n",
    "'left_mOMV':7,\n",
    "'right_mOMV':9,\n",
    "'left_lOMV':8,\n",
    "'right_lOMV':10,\n",
    "    \n",
    "'left_VIIb':5,\n",
    "'right_VIIb':6,\n",
    "    \n",
    "'left_mVIIIb':3,\n",
    "'right_mVIIIb':2,\n",
    "'left_lVIIIb':4,\n",
    "'right_lVIIIb':1,\n",
    "}\n",
    "\n",
    "\n",
    "# this is how the lateral/medial and left right hemisphere indices combine:\n",
    "roi_combs = {\n",
    "    'left_OMV':[7,8],\n",
    "    'right_OMV':[9,10],\n",
    "    'left_VIIb':[5],\n",
    "    'right_VIIb':[6],\n",
    "    'left_VIIIb':[3,4],\n",
    "    'right_VIIIb':[1,2],\n",
    "\n",
    "    'OMV':[7,8,9,10],\n",
    "    'lOMV':[8,10],\n",
    "    'mOMV':[7,9],\n",
    "    'VIIb':[5,6],\n",
    "    'VIIIb':[1,2,3,4],\n",
    "    'lVIIIb':[1,4],\n",
    "    'mVIIIb':[2,3],\n",
    "}\n",
    "\n",
    "roi_order = ['left_OMV','right_OMV','left_VIIb','right_VIIb','left_VIIIb','right_VIIIb']\n",
    "# roi_comb_order = ['mOMV','lOMV','VIIb','mVIIIb','lVIIIb']           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kernel = 6 # 1/kernel is the proportion of data in single moving average operation\n",
    "\n",
    "# angles\n",
    "angle_rot_mask = {\n",
    "    'left_OMV':0.75,\n",
    "    'right_OMV':0.25,\n",
    "    'left_VIIb':1.25,\n",
    "    'right_VIIb':1.75,\n",
    "    'left_VIIIb':0.75,\n",
    "    'right_VIIIb':0.25,\n",
    "\n",
    "}    \n",
    "\n",
    "# extents\n",
    "angle_roi_extents = {\n",
    "    'left_OMV':[14,32],\n",
    "    'right_OMV':[14,33],\n",
    "    'left_VIIb':[5,40],\n",
    "    'right_VIIb':[3,37],\n",
    "    'left_VIIIb':[-13,30],\n",
    "    'right_VIIIb':[-12,18],\n",
    "}   \n",
    "\n",
    "# angles\n",
    "ecc_rot_mask = {\n",
    "    'left_OMV':0.25,\n",
    "    'right_OMV':0.75,\n",
    "    'left_VIIb':0,\n",
    "    'right_VIIb':1,\n",
    "    'left_VIIIb':0.25,\n",
    "    'right_VIIIb':0.75,\n",
    "}\n",
    "\n",
    "# extents\n",
    "ecc_roi_extents = {\n",
    "    'left_OMV':[6,17],\n",
    "    'right_OMV':[4,15],\n",
    "    'left_VIIb':[-28,-2],\n",
    "    'right_VIIb':[-27,-1],\n",
    "    'left_VIIIb':[-90,-55],\n",
    "    'right_VIIIb':[-87,-57],\n",
    "\n",
    "}   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def weighted_moving_avg_ang(x_data,y_data,weights,kernel=6):\n",
    "\n",
    "    \"\"\"\n",
    "    this function was only used in initial version of manuscript\n",
    "    \"\"\"\n",
    "    \n",
    "    # first sort values based on x\n",
    "    order = np.argsort(x_data)\n",
    "    xo = x_data[order]\n",
    "    yo = y_data[order]\n",
    "    wo = weights[order]\n",
    "    n = len(weights)\n",
    "    kw = int(n/kernel)\n",
    "    \n",
    "    # initialize variables\n",
    "    ma_x = []\n",
    "    ma_y = []\n",
    "    ma_y_ci = []\n",
    "    # loop over bins\n",
    "    for i in range(n-kw):\n",
    "        valid_vertices = np.arange(len(wo))[i:i+kw]\n",
    "        valid_vertices = valid_vertices[~np.isnan(wo[valid_vertices])]\n",
    "        try:\n",
    "            ma_y_ci.append(pc.mean_ci_limits(yo[valid_vertices],w=wo[valid_vertices]))\n",
    "            ma_y.append(pc.mean(yo[valid_vertices],w=wo[valid_vertices]))\n",
    "            ma_x.append(np.average(xo[valid_vertices],weights=wo[valid_vertices]))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return np.array(ma_x), np.array(ma_y), np.array(ma_y_ci)\n",
    "\n",
    "def weighted_moving_avg_ecc(x_data,y_data,weights,kernel=6):\n",
    "\n",
    "    \"\"\"\n",
    "    this function was only used in initial version of manuscript\n",
    "    \"\"\"\n",
    "    \n",
    "    # first sort values based on x\n",
    "    order = np.argsort(x_data)\n",
    "    xo = x_data[order]\n",
    "    yo = y_data[order]\n",
    "    wo = weights[order]\n",
    "    n = len(weights)\n",
    "    kw = int(n/kernel)\n",
    "\n",
    "    # loop over bins\n",
    "    # initialize variables\n",
    "    ma_x = []\n",
    "    ma_y = []\n",
    "    ma_y_ci = []    \n",
    "    for i in range(n-kw):\n",
    "        valid_vertices = np.arange(len(wo))[i:i+kw]\n",
    "        valid_vertices = valid_vertices[~np.isnan(wo[valid_vertices])]\n",
    "\n",
    "        ma_x.append(np.average(xo[valid_vertices],weights=wo[valid_vertices]))\n",
    "        ma_y.append(np.average(yo[valid_vertices]))#,weights=wo[valid_vertices]))\n",
    "\n",
    "        # to match the ci with the circular version, find the value that needs to be added\n",
    "        # and subtracted from the mean value:\n",
    "        ci = sms.DescrStatsW(yo[valid_vertices],weights=wo[valid_vertices]).tconfint_mean()\n",
    "        half_ci = np.diff(ci)/2.\n",
    "        ma_y_ci.append(half_ci[0])\n",
    "        \n",
    "#     ma_y_ci = np.array(ma_y_ci)\n",
    "    \n",
    "    return np.array(ma_x), np.array(ma_y), np.array(ma_y_ci)\n",
    "\n",
    "def binned_avg_ang(x_data,y_data,weights,bin_edges):\n",
    "\n",
    "    \"\"\"\n",
    "    This function computes the circular weighted average\n",
    "    and a 95 CI for the mean\n",
    "    across y-data for every x-bin given in bin_edges.\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize variables\n",
    "    ma_x = []\n",
    "    ma_y = []\n",
    "    ma_y_ci = []\n",
    "    \n",
    "    # now loop over bins and compute mean and CI for each bin\n",
    "    for bi in range(len(bin_edges)-1):\n",
    "    \n",
    "        # determine vertices to use for this bin\n",
    "        # in the last bin, take values including upper limit\n",
    "        if bi == (len(bin_edges)-1):\n",
    "            valid_vertices = ((x_data>=bin_edges[bi])*(x_data<=bin_edges[bi+1]))\n",
    "        # in former bins, take values excluding upper limit\n",
    "        else:\n",
    "            valid_vertices = ((x_data>=bin_edges[bi])*(x_data<bin_edges[bi+1]))\n",
    "        \n",
    "        valid_verticies = valid_vertices[~np.isnan(valid_vertices)]\n",
    "            \n",
    "        # now only compute the values if there are 1 or more valid vertices\n",
    "        # (this is only relevant in individual subject data)\n",
    "        if valid_vertices.sum()>0:\n",
    "            ma_x.append(np.average(x_data[valid_vertices],weights=weights[valid_vertices]))\n",
    "            ma_y.append(pc.mean(y_data[valid_vertices],w=weights[valid_vertices]))\n",
    "            ma_y_ci.append(pc.mean_ci_limits(y_data[valid_vertices],w=weights[valid_vertices]))\n",
    "        else:\n",
    "            ma_x.append(np.nan)\n",
    "            ma_y.append(np.nan)\n",
    "            ma_y_ci.append(np.nan)\n",
    "    \n",
    "    return np.array(ma_x), np.array(ma_y), np.array(ma_y_ci)\n",
    "\n",
    "def binned_avg_ecc(x_data,y_data,weights,bin_edges):\n",
    "\n",
    "    \"\"\"\n",
    "    This function computes the weighted average\n",
    "    and a 95 CI for the mean\n",
    "    across y-data for every x-bin given in bin_edges.\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize variables\n",
    "    ma_x = []\n",
    "    ma_y = []\n",
    "    ma_y_ci = []\n",
    "\n",
    "    # now loop over bins and compute mean and CI for each bin\n",
    "    for bi in range(len(bin_edges)-1):\n",
    "    \n",
    "        # determine vertices to use for this bin\n",
    "        # in the last bin, take values including upper limit\n",
    "        if bi == (len(bin_edges)-1):\n",
    "            valid_vertices = ((x_data>=bin_edges[bi])*(x_data<=bin_edges[bi+1]))\n",
    "        # in former bins, take values excluding upper limit\n",
    "        else:\n",
    "            valid_vertices = ((x_data>=bin_edges[bi])*(x_data<bin_edges[bi+1]))\n",
    "\n",
    "        valid_verticies = valid_vertices[~np.isnan(valid_vertices)]\n",
    "        # now only compute the values if there are 1 or more valid vertices\n",
    "        # (this is only relevant in individual subject data)\n",
    "        if valid_vertices.sum()>3:\n",
    "            ma_x.append(np.average(x_data[valid_vertices],weights=weights[valid_vertices]))\n",
    "            ma_y.append(np.average(y_data[valid_vertices],weights=weights[valid_vertices]))\n",
    "            \n",
    "            # to match the ci with the circular version, find the value that needs to be added\n",
    "            # and subtracted from the mean value:\n",
    "            ci = sms.DescrStatsW(y_data[valid_vertices],weights=weights[valid_vertices]).tconfint_mean()\n",
    "            half_ci = np.diff(ci)/2.\n",
    "            ma_y_ci.append(half_ci[0])\n",
    "\n",
    "        else:\n",
    "            ma_x.append(np.nan)\n",
    "            ma_y.append(np.nan)\n",
    "            ma_y_ci.append(np.nan)\n",
    "    \n",
    "    return np.array(ma_x), np.array(ma_y), np.array(ma_y_ci)\n",
    "\n",
    "def weighted_moving_angle_avg(sj,mask,n_bins,avg_type ='moving'):\n",
    "\n",
    "    # load in the SUIT data for this subject\n",
    "    angles=np.ravel(pd.read_csv(os.path.join(flat_dir,'ang_flatdata_%s.csv'%str(sj)),header=None))\n",
    "    r2=np.ravel(pd.read_csv(os.path.join(flat_dir,'r2_flatdata_%s.csv'%str(sj)),header=None))\n",
    "    \n",
    "    # rotate angles so 0 is up and run from 0-2pi\n",
    "    angles += 1.5*np.pi\n",
    "    angles = np.mod(angles,np.pi*2)\n",
    "    \n",
    "    # create mask\n",
    "    v = np.zeros_like(masks).astype(bool)\n",
    "    for subroi in these_combs[mask]:        \n",
    "        v += (masks==mask_names[subroi])\n",
    "    \n",
    "    # rotate x values\n",
    "    rotation = angle_rot_mask[mask]\n",
    "    rx = np.ravel(rotate_via_numpy(x,y,rotation*np.pi)[0])\n",
    "    \n",
    "    # determine percentile bins:\n",
    "    sorted_rx = np.sort(copy.copy(rx[v]))\n",
    "    n = v.sum()\n",
    "    bin_width = np.int(np.round(n/(n_bins)))\n",
    "    bin_edge_indices = np.floor(np.linspace(0,n-1,n_bins+1)).astype(int)\n",
    "    bin_edges = sorted_rx[bin_edge_indices]\n",
    "       \n",
    "    # now that bin edges have been defined, add this to mask:\n",
    "    v *= (r2>0)\n",
    "    v *= (np.invert(np.isnan(angles)))\n",
    "    v *= (np.invert(np.isnan(r2)))\n",
    "\n",
    "    # invert angle data if left hemisphere\n",
    "    # this is done so both hemispheres show a 'v' shape \n",
    "    if 'left' in mask:\n",
    "        angledata = copy.copy(angles)\n",
    "        angledata = 2*np.pi-angledata\n",
    "    elif 'right' in mask:\n",
    "        angledata = copy.copy(angles)\n",
    "\n",
    "    # apply mask\n",
    "    x_data = rx[v]\n",
    "    y_data = angledata[v]\n",
    "    weights = r2[v]\n",
    "    \n",
    "    # actually compute the binned means\n",
    "    if avg_type == 'bins':\n",
    "        ma_x, ma_y, ma_y_ci = binned_avg_ang(x_data,y_data,weights,bin_edges)\n",
    "    elif avg_type == 'moving':\n",
    "        ma_x, ma_y, ma_y_ci = weighted_moving_avg_ang(x_data,y_data,weights,n_bins)\n",
    "\n",
    "    # convert to degrees\n",
    "    ma_y = np.degrees(ma_y)\n",
    "    ma_y_ci = np.degrees(ma_y_ci)\n",
    "    \n",
    "    return ma_x, ma_y, ma_y_ci\n",
    "\n",
    "def weighted_moving_ecc_avg(sj,mask,n_bins,avg_type='moving'):\n",
    "\n",
    "    # get SUIT data for this subject\n",
    "    eccs=np.ravel(pd.read_csv(os.path.join(flat_dir,'ecc_flatdata_%s.csv'%str(sj)),header=None))\n",
    "    r2=np.ravel(pd.read_csv(os.path.join(flat_dir,'r2_flatdata_%s.csv'%str(sj)),header=None))\n",
    "    \n",
    "    # create mask\n",
    "    v = np.zeros_like(masks).astype(bool)\n",
    "    for subroi in these_combs[mask]:        \n",
    "        v += (masks==mask_names[subroi])\n",
    "    \n",
    "    # rotate x values\n",
    "    rotation = ecc_rot_mask[mask]\n",
    "    rx = np.ravel(rotate_via_numpy(x,y,rotation*np.pi)[0])\n",
    "    \n",
    "    # determine percentile bins:\n",
    "    sorted_rx = np.sort(copy.copy(rx[v]))\n",
    "    n = v.sum()\n",
    "    bin_width = np.int(np.round(n/(n_bins)))\n",
    "    bin_edge_indices = np.floor(np.linspace(0,n-1,n_bins+1)).astype(int)\n",
    "    bin_edges = sorted_rx[bin_edge_indices]\n",
    "   \n",
    "    # now add this to mask:\n",
    "    v *= (np.invert(np.isnan(eccs)))\n",
    "    v *= (np.invert(np.isnan(r2)))\n",
    "    v *= (r2>0)\n",
    "\n",
    "    # apply mask\n",
    "    x_data = rx[v]\n",
    "    y_data = eccs[v]\n",
    "    weights = r2[v]\n",
    "    \n",
    "    # compute binned means:\n",
    "    if avg_type == 'moving':\n",
    "        ma_x, ma_y, ma_y_ci = weighted_moving_avg_ecc(x_data,y_data,weights,n_bins)    \n",
    "    elif avg_type == 'bins':\n",
    "        ma_x, ma_y, ma_y_ci = binned_avg_ecc(x_data,y_data,weights,bin_edges)\n",
    "\n",
    "    \n",
    "    return ma_x, ma_y, ma_y_ci\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polar angle plots\n",
    "### polar progressions for the differently split averaged subjects in separate plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pl.close('all')\n",
    "sjs = ['181','182','183','183_1','183_2']\n",
    "all_x = {}\n",
    "all_y = {}\n",
    "for sj in sjs:\n",
    "    \n",
    "    all_x[sj] = {}\n",
    "    all_y[sj] = {}\n",
    "\n",
    "    f = pl.figure(figsize=(1.7,2.75))\n",
    "\n",
    "    alpha = 1\n",
    "    lw = 1.5\n",
    "    ls = '-'\n",
    "    \n",
    "    for mi,mask in enumerate(roi_order):\n",
    "\n",
    "        # get data\n",
    "        ma_x, ma_y,ma_y_ci= weighted_moving_angle_avg(sj,mask,n_bins=10,avg_type='bins')\n",
    "\n",
    "        all_x[sj][mask] = ma_x\n",
    "        all_y[sj][mask] = ma_y\n",
    "\n",
    "        # remove nans\n",
    "        ma_x = ma_x[~np.isnan(ma_x)]\n",
    "        ma_y = ma_y[~np.isnan(ma_y)]\n",
    "        ma_y_ci = ma_y_ci[~np.isnan(ma_y_ci)]\n",
    "\n",
    "        # now plot\n",
    "        s = f.add_subplot(3,2,mi+1)\n",
    "        \n",
    "        c = get_roi_color(mask)\n",
    "\n",
    "        pl.fill_between(ma_x,ma_y+ma_y_ci,ma_y-ma_y_ci,color=c,alpha=1)\n",
    "\n",
    "        # add line at minimal angle\n",
    "        if 'VIIb' not in mask:\n",
    "            pl.axvline(ma_x[np.argmin(ma_y)],ls='--',c='k',dashes=(2,2))\n",
    "\n",
    "        # put down right lables\n",
    "        # labels are reversed, as data was reversed in left mask\n",
    "        if 'left' in mask:\n",
    "            pl.ylim(160,290)\n",
    "            pl.yticks([180,270],[r'$\\pi$',r'$\\pi/2$'])#['down','left'])\n",
    "        elif 'right' in mask:\n",
    "            pl.ylim(160,290)\n",
    "            pl.yticks([180,270],[r'$\\pi$',r'$3\\pi/2$'])#,['down','right'])\n",
    "\n",
    "        pl.xticks([np.nanmin(ma_x),np.nanmax(ma_x)])\n",
    "        sn.despine(offset=2)\n",
    "\n",
    "    pl.tight_layout()\n",
    "    f.savefig(os.path.join(fig_dir,'anglesurf_cluster_%s.pdf'%sj))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### polar progressions for the differently split averaged subjects in one plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pl.close('all')\n",
    "f = pl.figure(figsize=(1.7,2.75))\n",
    "lw = 1\n",
    "ls = '-'\n",
    "alpha =0.5\n",
    "sjs = ['181','182','183_1','183_2']\n",
    "\n",
    "for sj in sjs:\n",
    "\n",
    "    for mi,mask in enumerate(roi_order):\n",
    "\n",
    "        # get data\n",
    "        ma_x, ma_y,ma_y_ci = weighted_moving_angle_avg(sj,mask,n_bins=10,avg_type='bins')\n",
    "\n",
    "        # plot\n",
    "        c = get_roi_color(mask)\n",
    "        s = f.add_subplot(3,2,mi+1)\n",
    "        pl.fill_between(ma_x,ma_y+ma_y_ci,ma_y-ma_y_ci,color=c,alpha=alpha)\n",
    "\n",
    "        # add line at minimal angle\n",
    "        if 'VIIb' not in mask:\n",
    "            pl.axvline(ma_x[np.nanargmin(ma_y)],lw=1.5,ls='-',c='k', alpha=0.15)\n",
    "\n",
    "        # put down right lables\n",
    "        # labels are reversed, as data was reversed in left mask\n",
    "        if 'left' in mask:\n",
    "            pl.ylim(160,290)\n",
    "            pl.yticks([180,270],[r'$\\pi$',r'$\\pi/2$'])#['down','left'])\n",
    "        elif 'right' in mask:\n",
    "            pl.ylim(160,290)\n",
    "            pl.yticks([180,270],[r'$\\pi$',r'$3\\pi/2$'])#,['down','right'])\n",
    "\n",
    "        pl.xticks([np.nanmin(ma_x),np.nanmax(ma_x)])\n",
    "\n",
    "        sn.despine(offset=2)\n",
    "\n",
    "pl.tight_layout()\n",
    "f.savefig(os.path.join(fig_dir,'anglesurf_cluster_together.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### polar progressions across individual subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pl.close('all')\n",
    "\n",
    "# main figure\n",
    "f = pl.figure(figsize=(1.7,2.75))\n",
    "# figure with subject Ns\n",
    "f2 = pl.figure(figsize=(1.7,2.75))\n",
    "\n",
    "sjs = range(181)\n",
    "\n",
    "for mi,mask in enumerate(roi_order):\n",
    "    s = f.add_subplot(3,2,mi+1)\n",
    "    s2 = f2.add_subplot(3,2,mi+1)\n",
    "\n",
    "    # initialize variables\n",
    "    all_xs = []\n",
    "    all_ys = []\n",
    "\n",
    "    # now loop over subjects and compute angle\n",
    "    # for every 10-percentile bin along\n",
    "    # the cluster extent\n",
    "    for sj in sjs:\n",
    "    \n",
    "        # can't manage for all subjects (too little data)\n",
    "        try:\n",
    "            ma_x, ma_y,ma_y_ci = weighted_moving_angle_avg(sj,mask,n_bins=10,avg_type='bins')\n",
    "            all_xs.append(ma_x)\n",
    "            all_ys.append(ma_y)            \n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # the x is easy, simply the nanmean across subjects:\n",
    "    ma_x = np.nanmean(all_xs,axis=0)\n",
    "    \n",
    "    # for the y, things are slightly more complicated:\n",
    "    all_ys = np.array(all_ys)\n",
    "    ma_y = []\n",
    "    ma_y_ci = []\n",
    "    ns = []\n",
    "    # compute the circular mean and CI of mean for each bin across subjects:\n",
    "    for b in range(all_ys.shape[1]):\n",
    "        these_y = all_ys[:,b]\n",
    "        these_y = these_y[~np.isnan(these_y)]\n",
    "        ns.append(len(these_y))\n",
    "        # cannot always compute CI (only if there is certain concentration around mean)\n",
    "        try:\n",
    "            ci = np.degrees(pc.mean_ci_limits(np.radians(these_y)))\n",
    "        except:\n",
    "            ci = 360 # set to complete uncertainty\n",
    "\n",
    "        ma_y.append(np.degrees(pc.mean(np.radians(these_y))))\n",
    "        ma_y_ci.append(ci)\n",
    "    \n",
    "    # convert to numpy arrays\n",
    "    ma_y_ci = np.array(ma_y_ci)\n",
    "    ma_y = np.array(ma_y)\n",
    "\n",
    "    # now plot\n",
    "    c = get_roi_color(mask)\n",
    "    pl.sca(s)\n",
    "    pl.plot(ma_x,ma_y,color=c,ls=ls,lw=lw,alpha=1)\n",
    "    pl.fill_between(ma_x,ma_y-ma_y_ci,ma_y+ma_y_ci,color=c,alpha=0.5)\n",
    "\n",
    "    # put down right lables\n",
    "    # labels are reversed, as data was reversed in left mask\n",
    "    if 'left' in mask:\n",
    "        pl.ylim(160,290)\n",
    "        pl.yticks([180,270],[r'$\\pi$',r'$\\pi/2$'])#['down','left'])\n",
    "    elif 'right' in mask:\n",
    "        pl.ylim(160,290)\n",
    "        pl.yticks([180,270],[r'$\\pi$',r'$3\\pi/2$'])#,['down','right'])\n",
    "        \n",
    "    # ticks\n",
    "    pl.xticks([np.nanmin(ma_x),np.nanmax(ma_x)])\n",
    "\n",
    "    # now plot the Ns\n",
    "    pl.sca(s2)\n",
    "    pl.plot(ma_x,ns,c=c,lw=2)\n",
    "    pl.xticks([np.nanmin(ma_x),np.nanmax(ma_x)])\n",
    "    pl.yticks([0,len(sjs)])\n",
    "\n",
    "    # and some plot properties\n",
    "    pl.sca(s)\n",
    "    sn.despine(offset=2)\n",
    "    pl.sca(s2)\n",
    "    sn.despine(offset=2)\n",
    "\n",
    "# and figure properties\n",
    "pl.figure(f.number)\n",
    "pl.tight_layout()\n",
    "f.savefig(os.path.join(fig_dir,'anglesurf_cluster_together_subs.pdf'))\n",
    "\n",
    "pl.figure(f2.number)\n",
    "pl.tight_layout()\n",
    "f2.savefig(os.path.join(fig_dir,'anglesurf_cluster_together_subs_n.pdf'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eccentricity plots\n",
    "### eccentricity progressions for the differently split averaged subjects in separate plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sjs = ['181','182','183','183_1','183_2']\n",
    "\n",
    "pl.close('all')\n",
    "for sj in sjs:\n",
    "    \n",
    "    f = pl.figure(figsize=(1.5,2.75))\n",
    "\n",
    "    for mi,mask in enumerate(roi_order):\n",
    "\n",
    "        s = f.add_subplot(3,2,mi+1)\n",
    "\n",
    "        # get data\n",
    "#         ma_x, ma_y,ma_y_ci = weighted_moving_ecc_avg(sj,mask,n_bins=6,avg_type='moving')\n",
    "        ma_x, ma_y,ma_y_ci = weighted_moving_ecc_avg(sj,mask,n_bins=8,avg_type='bins')\n",
    "        # plot\n",
    "        c = get_roi_color(mask)\n",
    "#         pl.plot(ma_x,ma_y,lw=1.5,color=c)\n",
    "        pl.fill_between(ma_x,ma_y+ma_y_ci,ma_y-ma_y_ci,color=c,alpha=1)\n",
    "\n",
    "        # add ticks\n",
    "        if (mask == 'left_OMV') + (mask == 'right_OMV'):\n",
    "            pl.yticks([0,0.5],['0','0.5'])\n",
    "            pl.ylim(0,0.5)\n",
    "        elif (mask == 'left_VIIb') + (mask == 'right_VIIb'):\n",
    "            pl.yticks([0,4],['0','4.0'])\n",
    "            pl.ylim(0,4)\n",
    "        elif (mask == 'left_VIIIb') + (mask == 'right_VIIIb'):\n",
    "            pl.yticks([0,8],['0','8.0'])\n",
    "            pl.ylim(0,8)\n",
    "        pl.xticks([np.nanmin(ma_x),np.nanmax(ma_x)])\n",
    "        sn.despine(offset=2)\n",
    "\n",
    "    pl.tight_layout()\n",
    "    f.savefig(os.path.join(fig_dir,'eccsurf_cluster_%s.pdf'%sj))#,dpi=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### eccentricity progressions for the differently split averaged subjects in one plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pl.close('all')\n",
    "f = pl.figure(figsize=(1.7,2.75))\n",
    "lw = 1\n",
    "ls = '-'        \n",
    "alpha =0.5\n",
    "\n",
    "\n",
    "sjs = ['181','182','183_1','183_2']\n",
    "for sj in sjs:\n",
    "    \n",
    "\n",
    "    for mi,mask in enumerate(roi_order):\n",
    "\n",
    "        #get data\n",
    "        ma_x, ma_y,ma_y_ci = weighted_moving_ecc_avg(sj,mask,n_bins=8,avg_type='bins')\n",
    "\n",
    "        # plot\n",
    "        c = get_roi_color(mask)\n",
    "        s = f.add_subplot(3,2,mi+1)\n",
    "        pl.fill_between(ma_x,ma_y+ma_y_ci,ma_y-ma_y_ci,color=c,alpha=alpha)\n",
    "\n",
    "        # ticks\n",
    "        if (mask == 'left_OMV') + (mask == 'right_OMV'):\n",
    "            pl.yticks([0,0.5],['0','0.5'])\n",
    "            pl.ylim(0,0.5)\n",
    "        elif (mask == 'left_VIIb') + (mask == 'right_VIIb'):\n",
    "            pl.yticks([0,4],['0','4.0'])\n",
    "            pl.ylim(0,4)\n",
    "        elif (mask == 'left_VIIIb') + (mask == 'right_VIIIb'):\n",
    "            pl.yticks([0,8],['0','8.0'])\n",
    "            pl.ylim(0,8)\n",
    "        pl.xticks([np.nanmin(ma_x),np.nanmax(ma_x)])\n",
    "\n",
    "        sn.despine(offset=2)\n",
    "\n",
    "pl.tight_layout()\n",
    "f.savefig(os.path.join(fig_dir,'eccsurf_cluster_together.pdf'))#,dpi=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### polar progressions across individual subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pl.close('all')\n",
    "\n",
    "# main figure\n",
    "f = pl.figure(figsize=(1.7,2.75))\n",
    "# figure with subject Ns\n",
    "f2 = pl.figure(figsize=(1.7,2.75))\n",
    "\n",
    "sjs = range(181)\n",
    "\n",
    "for mi,mask in enumerate(roi_order):\n",
    "    s = f.add_subplot(3,2,mi+1)\n",
    "    s2 = f2.add_subplot(3,2,mi+1)\n",
    "\n",
    "    # initialize variables\n",
    "    all_xs = []\n",
    "    all_ys = []\n",
    "\n",
    "    # now loop over subjects and compute angle\n",
    "    # for every 10-percentile bin along\n",
    "    # the cluster extent\n",
    "    for sj in sjs:\n",
    "    \n",
    "        # can't manage for all subjects (too little data)\n",
    "        try:\n",
    "            ma_x, ma_y,ma_y_ci = weighted_moving_ecc_avg(sj,mask,n_bins=8,avg_type='bins')\n",
    "            all_xs.append(ma_x)\n",
    "            all_ys.append(ma_y)            \n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # the x is easy, simply the nanmean across subjects:\n",
    "    ma_x = np.nanmean(all_xs,axis=0)\n",
    "    \n",
    "    # for the y, things are slightly more complicated:\n",
    "    all_ys = np.array(all_ys)\n",
    "    ma_y = []\n",
    "    ma_y_ci = []\n",
    "    ns = []\n",
    "    # compute the circular mean and CI of mean for each bin across subjects:\n",
    "    for b in range(all_ys.shape[1]):\n",
    "        these_y = all_ys[:,b]\n",
    "        these_y = these_y[~np.isnan(these_y)]\n",
    "        ns.append(len(these_y))\n",
    "        # cannot always compute CI (only if there is certain concentration around mean)\n",
    "        try:\n",
    "            ci = np.degrees(pc.mean_ci_limits(np.radians(these_y)))\n",
    "        except:\n",
    "            ci = 360 # set to complete uncertainty\n",
    "\n",
    "        ma_y.append(np.degrees(pc.mean(np.radians(these_y))))\n",
    "        ma_y_ci.append(ci)\n",
    "    \n",
    "    # convert to numpy arrays\n",
    "    ma_y_ci = np.array(ma_y_ci)\n",
    "    ma_y = np.array(ma_y)\n",
    "\n",
    "    # now plot\n",
    "    c = get_roi_color(mask)\n",
    "    pl.sca(s)\n",
    "    pl.plot(ma_x,ma_y,color=c,ls=ls,lw=lw,alpha=1)\n",
    "    pl.fill_between(ma_x,ma_y-ma_y_ci,ma_y+ma_y_ci,color=c,alpha=0.5)\n",
    "\n",
    "    # ticks\n",
    "    if (mask == 'left_OMV') + (mask == 'right_OMV'):\n",
    "        pl.yticks([0,2],['0','2'])\n",
    "        pl.ylim(0,2)\n",
    "    elif (mask == 'left_VIIb') + (mask == 'right_VIIb'):\n",
    "        pl.yticks([0,4],['0','4.0'])\n",
    "        pl.ylim(0,4)\n",
    "    elif (mask == 'left_VIIIb') + (mask == 'right_VIIIb'):\n",
    "        pl.yticks([0,8],['0','8.0'])\n",
    "        pl.ylim(0,8)\n",
    "        \n",
    "    # ticks\n",
    "    pl.xticks([np.nanmin(ma_x),np.nanmax(ma_x)])\n",
    "\n",
    "    # now plot the Ns\n",
    "    pl.sca(s2)\n",
    "    pl.plot(ma_x,ns,c=c,lw=2)\n",
    "    pl.xticks([np.nanmin(ma_x),np.nanmax(ma_x)])\n",
    "    pl.yticks([0,len(sjs)])\n",
    "\n",
    "    # and some plot properties\n",
    "    pl.sca(s)\n",
    "    sn.despine(offset=2)\n",
    "    pl.sca(s2)\n",
    "    sn.despine(offset=2)\n",
    "\n",
    "# and figure properties\n",
    "pl.figure(f.number)\n",
    "pl.tight_layout()\n",
    "f.savefig(os.path.join(fig_dir,'eccsurf_cluster_together_subs.pdf'))\n",
    "\n",
    "pl.figure(f2.number)\n",
    "pl.tight_layout()\n",
    "f2.savefig(os.path.join(fig_dir,'eccsurf_cluster_together_subs_n.pdf'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [analysis]",
   "language": "python",
   "name": "Python [analysis]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
